# Synthetic Image Detection Benchmark

This project is a framework for benchmarking several state-of-the-art synthetic image detection models.

## Installation

## Install dependecies 

Create a new environment named `pytorch_env`:

```bash
conda create --name pytorch_env python=3.11
conda activate pytorch_env
```

and then install pytorch dependecies 

```bash
conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia
```

> **Note** :sparkles:: This framework has been **tested** with Python version `3.11.7` and PyTorch `2.1.2`. However, it **should work** with other versions as well. Please ensure that your PyTorch version is **greater than 2.0**. :warning:

Install additional dependencies: 

```bash
pip install -r requirements.txt
```

To run the Dire model, mpi4py is required. You can install it using Conda with the following command:

```bash
conda install -c conda-forge mpi4py mpich
```


## Integrated Models

The following models have been integrated. Note that for some of these models, there are multiple pretrained instances, trained on different images generated by various generative models such as ProGAN, StyleGAN, and Latent Diffusion, etc.

|Model Name|Paper Title|Original Code|
|:--------:|:------:|:------:|
|CNNDetect|CNN-generated images are surprisingly easy to spot...for now | [:link:](https://github.com/peterwang512/CNNDetection)|
|DIMD| On the detection of synthetic images generated by diffusion models. | [:link:](https://github.com/grip-unina/DMimageDetection)|
|FreDetect|Leveraging Frequency Analysis for Deep Fake Image Recognition | [:link:](https://github.com/RUB-SysSec/GANDCTAnalysis)|
|Fusing|Fusing global and local features for generalized AI-synthesized image detection| [:link:](https://github.com/littlejuyan/FusingGlobalandLocal)|
|GramNet|Global Texture Enhancement for Fake Face Detection In the Wild | [:link:](https://github.com/liuzhengzhe/Global_Texture_Enhancement_for_Fake_Face_Detection_in_the-Wild)|
|LGrad|Learning on Gradients: Generalized Artifacts Representation for GAN-Generated Images Detection | [:link:](https://github.com/chuangchuangtan/LGrad)|
|Dire|DIRE for Diffusion-Generated Image Detection | [:link:](https://github.com/ZhendongWang6/DIRE)|
|UnivFD|Towards Universal Fake Image Detectors that Generalize Across Generative Models | [:link:](https://github.com/Yuheng-Li/UniversalFakeDetect)|
|NPR|Rethinking the Up-Sampling Operations in CNN-based Generative Network for Generalizable Deepfake Detection|[:link:](https://github.com/chuangchuangtan/NPR-DeepfakeDetection)|
|RPTC |Rich and Poor Texture Contrast: A Simple yet Effective Approach for AI-generated Image Detection | |
|Rine |Leveraging Representations from Intermediate Encoder-blocks for Synthetic Image Detection | [:link:](https://github.com/mever-team/rine) |

## Usage

### Run model on multiple images 

To run the model on a directory containing images, use the following command:

```bash

python test.py --dataPath <root_path_to_images>

```

This command executes the model using the default selection, which is UnivFD. If you wish to use a different model, you can specify it using the `--modelName` flag. For example, to use the CNNDetect model, the command would be:

```bash
python test.py --dataPath <root_path_to_images> --modelName=CNNDetect
```

The models supported by this framework are listed in the table above. When selecting a model using the --modelName flag, ensure you use one of the valid names as specified below. These names correspond to the models' implementations and must be used exactly as shown to ensure proper function invocation:

```python
VALID_MODELS = ['CNNDetect', 'FreqDetect', 'Fusing', 'GramNet', 'LGrad', 'UnivFD', 'RPTC', 'Rine', 'DIMD', 'NPR', 'Dire']
```

You need also to define the path to the pretanined weights with the `--cptk` flag
To run the model with pretrained weights, you must provide the path to these weights using the `--ckpt` flag. Ensure you replace `<path_to_pretrained_weights>` with the actual file path to your pretrained model weights.

```bash
python test.py --dataPath <root_path_to_images> --modelName=CNNDetect --cptk <path_to_pretrained_weights>

```

Replace `<root_path_to_images>` with the actual path to your directory of images, and `<path_to_pretrained_weights>` with the path to the pretrained weights file. 

You can download the pretrained weights here: [Google Drive](URL_HERE)


| Model Name    | Ptranined Weights File Name                                       | Description |
|---------------|-------------------------------------------------------------------|-------------|
| **CNNDetect** | weights/cnndetect/blur_jpg_prob0.1.pth                            |             |
|               | weights/cnndetect/blur_jpg_prob0.5.pth                            |             |
| **DIMD**      | weights/dimd/corvi22_latent_model.pth                             |             |
|               | weights/dimd/corvi22_progan_model.pth                             |             |
|               | weights/dimd/gandetection_resnet50nodown_progan.pth               |             |
|               | weights/dimd/gandetection_resnet50nodown_stylegan2.pth            |             |
| **Dire**      | weights/dire/lsun_adm.pth                                         |             |
|               | weights/dire/lsun_iddpm.pth                                       |             |
|               | weights/dire/lsun_pndm.pth                                        |             |
|               | weights/dire/lsun_stylegan.pth                                    |             |
| **FreqDetect**| weights/freqdetect/DCTAnalysis.pth                                |             |
| **UnivFD**    | weights/univfd/fc_weights..pth                                    |             |
| **Fusing**    | weights/fusing/PSM.pth                                            |             |
| **GramNet**   | weights/gramnet/Gram.pth                                          |             |
| **LGrad**     | weights/lgrad/LGrad-1class-Trainon-Progan_horse.pth               |             |
|               | weights/lgrad/LGrad-2class-Trainon-Progan_chair_horse.pth         |             |
|               | weights/lgrad/LGrad-4class-Trainon-Progan_car_cat_chair_horse.pth |             |
|               | weights/lgrad/LGrad.pth                                           |             |
| **LNP**       | weights/lnp/LNP.pth                                               |             |
| **NPR**       | weights/npr/NPR.pth                                               |             |
| **Rine**      | weights/rine/model_1class_trainable.pth                           |             |
|               | weights/rine/model_2class_trainable.pth                           |             |
|               | weights/rine/model_4class_trainable.pth                           |             |
|               | weights/rine/model_ldm_trainable.pth                              |             |


To save the predictions, specify an output file using the `--predictionsFile` flag. For example:

```bash
python test.py --dataPath <root_path_to_images> --predictionsFile <path_to_output_file>
```

#### Additional parameters

To resize images, use the `--resizeSize` flag followed by the desired dimension. f no resize size is specified, the default behavior is to apply no resizing. For example, to resize images to 256x256 pixels, you would use:
```bash
--resizeSize=256
```

To crop images, utilize the `--cropSize` flag similarly. The default crop size is set to 256 pixels, meaning if no crop size is specified, images will be cropped to 256x256 pixels by default. For example, to crop images to 256x256 pixels, the correct flag is:
```bash
--cropSize=256
```

:warning: Important Note: For models such as `UnivFD` and `Rine`, which are based on [CLIP](https://openai.com/research/clip), the input size must be set to 224x224 pixels due to CLIP's specific input size requirements. Therefore, use `--resizeSize=224` for these models. 


> *Important Note on Resizing*: The impact of resizing on the results cannot be overstated. For certain models, resizing can significantly improve outcomes, while for others, it may detract from performance. This effect is closely tied to the original resolution of the input images. Specifically, in the case of high-resolution images, resizing becomes a crucial factor to consider. For a deeper insight into how resizing affects model performance, please refer to the Evaluation Section.

### Evaluate on a dataset

This produces and saves several evaluation metrics, such as accuracy, average precision, and confusion matrix.
